{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"/scratch/users/k21113539/SR-UNet\")\n",
    "from models.unet3d.model import BUNet3D,UNet3D\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import ants\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from torchviz import make_dot\n",
    "from colossalai.utils import load_checkpoint\n",
    "from colossalai.initialize import launch,initialize\n",
    "import colossalai\n",
    "from colossalai.trainer import Trainer, hooks\n",
    "import h5py as h5\n",
    "from dataloaders import get_synth_dhcp_dataloader, get_synth_hcp_dataloader\n",
    "import torchio as tio\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback invoked by the IPython interact method for scrolling and modifying the alpha blending\n",
    "# of an image stack of two images that occupy the same physical space.\n",
    "def display_image(image_z, image):\n",
    "    img = image[:, :, image_z]\n",
    "    plt.imshow(sitk.GetArrayViewFromImage(img), cmap=plt.cm.Greys_r)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def load_model(model_path:str):\n",
    "    model = torch.load(model_path)\n",
    "    model.train()\n",
    "    return model\n",
    "\n",
    "def load_image(mode :str = 'h5', \n",
    "               paths = ['/scratch/prj/bayunet/dhcp_lores/preprocessed_h5/sub-CC01104XX07.h5'],\n",
    "               dataset = 'dhcp',\n",
    "               data_dir = '/home/viscent/hdd/dhcp/dhcp_lores/',):\n",
    "    if mode == 'h5':\n",
    "        with h5.File(paths[0],'r') as f:\n",
    "            image = f['image_t1'][...].astype(np.float32)\n",
    "            target = f['gt_t1'][...].astype(np.float32)\n",
    "        image_tensor = torch.from_numpy(image).unsqueeze(0).unsqueeze(0).cuda()\n",
    "        target_tensor = torch.from_numpy(target).unsqueeze(0).unsqueeze(0).cuda()\n",
    "        return image_tensor,target_tensor\n",
    "    elif mode == 'sitk':\n",
    "        image = sitk.ReadImage(paths[0])\n",
    "        target = sitk.ReadImage(paths[1])\n",
    "        image = sitk.GetArrayFromImage(image)\n",
    "        target = sitk.GetArrayFromImage(target)\n",
    "        image_tensor = torch.from_numpy(image).unsqueeze(0).unsqueeze(0).cuda()\n",
    "        target_tensor = torch.from_numpy(target).unsqueeze(0).unsqueeze(0).cuda()\n",
    "        return image_tensor,target_tensor\n",
    "    elif mode == 'npy':\n",
    "        image = np.load(paths[0])\n",
    "        target = np.load(paths[1])\n",
    "        image_tensor = torch.from_numpy(image).unsqueeze(0).cuda()\n",
    "        target_tensor = torch.from_numpy(target).unsqueeze(0).cuda()\n",
    "        return image_tensor,target_tensor\n",
    "    elif mode == 'dataloader':\n",
    "        if dataset == 'dhcp':\n",
    "            dataloaders, val_loader = get_synth_dhcp_dataloader(data_dir=data_dir,\n",
    "                                                                batch_size=1,\n",
    "                                                                num_samples=50,\n",
    "                                                                input_modalities=[\"t1\"],\n",
    "                                                                output_modalities=[\"t1\"],\n",
    "                                                                output_dir=data_dir,\n",
    "                                                                n_splits=5,\n",
    "                                                                augmentation=False,\n",
    "                                                                down_factor=5,)\n",
    "        elif dataset == 'hcp':\n",
    "            dataloaders, val_loader = get_synth_hcp_dataloader(data_dir=data_dir,\n",
    "                                                                batch_size=1,\n",
    "                                                                num_samples=50,\n",
    "                                                                input_modalities=[\"t1\"],\n",
    "                                                                output_modalities=[\"t1\"],\n",
    "                                                                output_dir=data_dir,\n",
    "                                                                n_splits=5,\n",
    "                                                                augmentation=False,\n",
    "                                                                down_factor=5,)\n",
    "        image_tensor, target_tensor = next(iter(val_loader))\n",
    "        image_tensor = image_tensor.cuda()\n",
    "        target_tensor = target_tensor.cuda()\n",
    "        return image_tensor,target_tensor\n",
    "\n",
    "def plot_latent(model):\n",
    "    encoder_weights = next(model.encoders[-1].parameters())\n",
    "    encoder_weights = encoder_weights.cpu().detach().numpy()\n",
    "    encoder_weights= np.expand_dims(encoder_weights,axis=1)\n",
    "    encoder_weights = np.repeat(encoder_weights, 128, axis=1)\n",
    "    if hasattr(model, 'enc_mu'):\n",
    "        fig,(ax1,ax2) = plt.subplots(1,2)\n",
    "        im1 = ax1.imshow(encoder_weights)\n",
    "        ax1.set_title(\"encoder weights\")\n",
    "        divider = make_axes_locatable(ax1)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        fig.colorbar(im1, cax=cax, orientation=\"vertical\")\n",
    "\n",
    "        latent_weights = next(model.mu.parameters())\n",
    "        latent_weights = latent_weights.cpu().detach().numpy()\n",
    "        latent_weights = np.repeat(latent_weights, 128, axis=1)\n",
    "\n",
    "        im2 = ax2.imshow(encoder_weights)\n",
    "        ax2.set_title(\"latent weights\")\n",
    "        divider = make_axes_locatable(ax2)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        fig.colorbar(im2, cax=cax, orientation=\"vertical\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        fig = plt.imshow(encoder_weights)\n",
    "        plt.title(\"encoder weights\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    # plt.savefig(OUTPUT_PREFIX+\"_encoder_weights.png\")\n",
    "\n",
    "def infer(model,image_tensor):\n",
    "    output_tensor = model(image_tensor)\n",
    "    return output_tensor\n",
    "\n",
    "def get_metrics(output_tensor,target_tensor, model, mu_q = None, logvar_q = None):\n",
    "    im = target_tensor\n",
    "    im_hat = output_tensor\n",
    "    mse = torch.nn.MSELoss()(im, im_hat)\n",
    "    mse.backward()\n",
    "    print('mse:', mse.cpu().detach().numpy())\n",
    "    if hasattr(model, 'enc_mu'):\n",
    "        mu_p, logvar_p = model.enc_mu,model.enc_logvar\n",
    "        # kl = (0.5 * ((torch.ones_like(logvar_p)-torch.ones_like(logvar_p)) + (mu_p-mu_q)**2 / torch.ones_like(logvar_p).exp() - 1 + (torch.ones_like(logvar_p)).exp() / (torch.ones_like(logvar_p)).exp() )).sum()\n",
    "        # kl = (0.5 * ((logvar_q-logvar_p) + (mu_p-mu_q)**2 / logvar_q.exp() - 1 + logvar_p.exp() / logvar_q.exp())).mean()\n",
    "        kl = 0.5 * (logvar_p.exp() + mu_p**2 - 1 - logvar_p).sum()\n",
    "        # kl = 0.5 * ((logvar_q-logvar_p) - 3 + (mu_p - mu_q) / logvar_q.exp() * (mu_p-mu_q) + torch.trace)\n",
    "        # kl = torch.sum(kl)\n",
    "        FE_simple = mse + 0.00025 * kl\n",
    "        print('kl:', kl.cpu().detach().numpy())\n",
    "        print('Free energy:', FE_simple.cpu().detach().numpy())\n",
    "\n",
    "def plot_output(image_tensor,output_tensor,target_tensor):\n",
    "    image_tensor = image_tensor.cpu().squeeze().squeeze().detach().numpy().astype(np.float32)\n",
    "    output_tensor = output_tensor.cpu().squeeze().squeeze().detach().numpy().astype(np.float32)\n",
    "    target_tensor = target_tensor.cpu().squeeze().squeeze().detach().numpy().astype(np.float32)\n",
    "    fig,(ax1,ax2,ax3) = plt.subplots(1,3)\n",
    "    im1 = ax1.imshow(image_tensor[image_tensor.shape[0]//2,:,:],cmap='gray')\n",
    "    ax1.set_title(\"image\")\n",
    "\n",
    "\n",
    "    im2 = ax2.imshow(output_tensor[output_tensor.shape[0]//2,:,:],cmap='gray')\n",
    "    ax2.set_title(\"output\")\n",
    "    \n",
    "    \n",
    "    im3 = ax3.imshow(target_tensor[target_tensor.shape[0]//2,:,:],cmap='gray')\n",
    "    ax3.set_title(\"target\")\n",
    "    fig.show()\n",
    "# Callback invoked when the sitkMultiResolutionIterationEvent happens, update the index into the\n",
    "# metric_values list.\n",
    "def update_multires_iterations():\n",
    "    global metric_values, multires_iterations\n",
    "    multires_iterations.append(len(metric_values))\n",
    "    \n",
    "def registration_sitk(fixed_image, moving_image):\n",
    "    initial_transform = sitk.CenteredTransformInitializer(\n",
    "        fixed_image,\n",
    "        moving_image,\n",
    "        sitk.Euler3DTransform(),\n",
    "        sitk.CenteredTransformInitializerFilter.GEOMETRY,\n",
    "    )\n",
    "\n",
    "    moving_resampled = sitk.Resample(\n",
    "        moving_image,\n",
    "        fixed_image,\n",
    "        initial_transform,\n",
    "        sitk.sitkLinear,\n",
    "        0.0,\n",
    "        moving_image.GetPixelID(),\n",
    "    )\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "\n",
    "    # Similarity metric settings.\n",
    "    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetMetricSamplingPercentage(0.01)\n",
    "\n",
    "    registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "\n",
    "    # Optimizer settings.\n",
    "    registration_method.SetOptimizerAsGradientDescent(\n",
    "        learningRate=1.0,\n",
    "        numberOfIterations=100,\n",
    "        convergenceMinimumValue=1e-6,\n",
    "        convergenceWindowSize=10,\n",
    "    )\n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift()\n",
    "\n",
    "    # Setup for the multi-resolution framework.\n",
    "    registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[4, 2, 1])\n",
    "    registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2, 1, 0])\n",
    "    registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n",
    "\n",
    "    # Don't optimize in-place, we would possibly like to run this cell multiple times.\n",
    "    registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
    "\n",
    "\n",
    "    final_transform = registration_method.Execute(\n",
    "        sitk.Cast(fixed_image, sitk.sitkFloat32), sitk.Cast(moving_image, sitk.sitkFloat32)\n",
    "    )\n",
    "    moving_resampled = sitk.Resample(\n",
    "        moving_image,\n",
    "        fixed_image,\n",
    "        final_transform,\n",
    "        sitk.sitkLinear,\n",
    "        0.0,\n",
    "        moving_image.GetPixelID(),\n",
    "    )\n",
    "    return moving_resampled\n",
    "\n",
    "def resample(image):\n",
    "    target_shape = (108, 145, 145)\n",
    "    spacing = [1.0,1.0,1.0]\n",
    "    spacing = np.array(spacing)\n",
    "    resample_transform = tio.Resample(target=spacing)\n",
    "    resize_transform = tio.Resize(target_shape=target_shape)\n",
    "    transform  = tio.Compose([resample_transform,resize_transform])\n",
    "    return transform(image)\n",
    "\n",
    "def downSample(image):\n",
    "    spacing = [1.0,1.0,1.0]\n",
    "    spacing = np.array(spacing)\n",
    "    spacing *= 5\n",
    "    target_shape = (108, 145, 145)\n",
    "    factor = spacing[2] / spacing[0]\n",
    "    resize_transform = tio.Resize(target_shape=target_shape)\n",
    "    resample_transform = tio.Resample(target=spacing)\n",
    "    blur_transform = tio.RandomBlur(3)\n",
    "    transform  = tio.Compose([resample_transform,resize_transform,blur_transform])\n",
    "    return transform(image)\n",
    "\n",
    "\n",
    "def registration_ants(fixed_image, moving_image):\n",
    "    fixed_array = sitk.GetArrayFromImage(fixed_image)\n",
    "    moving_array = sitk.GetArrayFromImage(moving_image)\n",
    "    fixed_ants = ants.from_numpy(fixed_array)\n",
    "    moving_ants = ants.from_numpy(moving_array)\n",
    "    ret = ants.registration(fixed_ants, moving_ants,verbose=True)\n",
    "    image = ret['warpedmovout'].numpy()\n",
    "    image = sitk.GetImageFromArray(image)\n",
    "    image.CopyInformation(fixed_image)\n",
    "    return image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff91d6d771b37266b23766d79b0c697874f607c0cce11e1250457dff8738e4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
